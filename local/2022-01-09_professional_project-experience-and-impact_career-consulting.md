The following is a list of key projects I have worked along with business impact during my time as a data science consultant. This may be useful as a supplement to reviewing my resume and to highlight the depth and breadth of my consulting experience.

- BCG feature store ‘Lighthouse’ - Stakeholder engagement and team leadership to develop a scalable high frequency data and feature store
- Payroll contract pricing - B2B contract pricing, data issues, ML, client training
    - Stakeholder engagement
- Wholesaler pricing - $1b promo spend optimised. B2B, promotion effectiveness, RRP
- BCG risk and best practice ring-fence - Stakeholder engagement to assess project risk and ensure high quality deliverables
- Survey data predictive value - New revenue streams, use case and launch recommendation, rigorous ML based framework
    - Survey data expertise and sophisticated ML solution
- COVID employment recovery research
- Consumer goods - Order replenishment
- High end fashion retailer - $30m personalization pilot, sales lift, offers and migration, many new techs and frameworks
    - Product analytics and big data
- Chatbot for survey engagement - New business capability and revenue streams, multi-disciplinary; advanced ML and python infrastructure
- Text analytics capability - New business capability and revenue streams, advanced ML and sales
- Government infrastructure end-user research - Measuring end-user satisfaction with large scale infrastructure project affecting all Australians

## BCG feature store ‘Lighthouse’
#### Stakeholder engagement and team leadership to develop a scalable high frequency data and feature store

- Goal
    - Worked on an internal project to make data assets readily available to case teams, to support quick turn around of time sensitive due diligence tasks, proposals, and client projects.
- Impact
    - We have increased the number of available datasets from ~20 to 40 in the past six months, and are seeing double digit growth in usage and billing allocation quarter over quarter.
    - Have developed technical and documented processes to rapidly onboard junior data scientists, so they can quickly add new datasets, with standards for end user focused documentation
    - Applied data assets to support client proposals, such as using footfall data as a proxy for store revenue
- Challenges
    - Lack of end user focused documentation
    - Leading a team of four junior data scientists
    - Needing to create the workstream from scratch, getting feedback and buy-in
- Skills and learnings
    - Team leadership and mentorship
    - Project management best practices
    - Effectively engaging with a variety of stakeholders

## Payroll contract pricing
#### B2B contract pricing, data issues, ML, client training

- Goal
    - We helped a B2B payroll service provider assess ideal contract pricing to maximise profit and reduce churn.
- Impact
    - We produced a simple, rules based approach to empower sales team to drive towards ideal contract pricing with a minimum of iterations; the increased speed resulted in reduced internal costs due to iterations, and faster contract turn around time with customers
    - We were able to tie this research with churn analysis to show no significant impact of initial price or price increases on churn rate, leading to increased willingness to engage in customer negotiations and increased profit.
- Challenges
    - Client had absorbed several smaller payroll providers, data was messy with over 50 different excel files provided, and relatively few database dumps. High security requirements and client infrastructure
    - Difficult to define how customers being charged as payroll is variable.
    - Remote working, limited time with west coast, east coast, Europe.
    - Training the Nacent data science team on data ingestion, codebase and methodology.
- Skills and learnings
    - Managing multiple data sources and data documentation
    - Managing codebase across whole team (myself plus two senior data scientists and lead)
    - Working with non-technical counterparts to provide robust data science approach and convert into simple, valid, rules based approach.

## Wholesaler pricing
#### $1b promo spend optimized. B2B, promotion effectiveness, RRP

- Goal
    - Worked with a B2B food distribution company to improve the effectiveness of their promotions with the goal of increasing purchase volume.
- Impact
    - $1b of promo spend optimized
    - We created an analytics pipeline to attribute historic promotion impact, and used this to recommend fund reallocation towards high performing promos
    - We provided analysis and recommendations to client for ideal recommended retail price, to optimise for multiple metrics (volume, revenue, profit), and guardrail conditions (minimum profit, competitive pricing), as well as highlighting elastic vs inelastic product sets.
- Challenges
    - Many categories, subcategories and SKUs, hard to generalise results
    - Complex promotion systems, i.e. vendor, client and customer contribution,
    - Required complex allocation system for overlapping timing windows, fill forward, cannibalisation
- Skills and learnings
    - Deeper insight into B2B wholesaler space and complex business rules
    - Further opportunity to mentor two junior data scientists
    - Started developing own frameworks around data engineering and pyspark comfort

## BCG risk and best practice ring-fence
#### Stakeholder engagement to assess project risk and ensure high quality deliverables

- Goal
    - Ensuring high quality projects and deliverables for our clients is BCG’s highest priority. I joined a ring-fence team which focused on providing project support to assess project risk and best practices, to ensure high quality outputs.
- Impact
    - Audited around 20 live cases across several attributes including legal, data use, teaming, infrastructure, modelling
    - Provided first hand coaching and review of codebases with junior team members, to support busy case leadership teams
    - Improved the auditing and onboarding process to help the ring-fence team scale and rotate new team members
- Challenges
    - Worked directly with busy BCG partners to explain audit process, provide guidance, and expert input on best practice
    - Quickly absorbing current best practice standards so I could provide expertise to teams
- Skills and learnings
    - Developed relationships with BCG leadership
    - Rapidly improved my python skills to provide expertise to case teams on successful python project delivery

## Survey data predictive value
#### New revenue streams, use case and launch recommendation, rigorous ML based framework

- Goal
    - We worked with a political polling data vendor to assess and recommend additional revenue streams for their data.
- Impact
    - We were able to find additional use cases and prove efficacy through robust data science methods.
    - After rigorous experimentation and benchmarking, we found evidence of a slight improvement in ability to predict near-term unemployment using client data and historic BLS unemployment measures. We showed the data was valuable.
    - We provided recommendations to organisation on improvements to data collection breadth and depth and recommended ‘no launch’, with optimism of seeing better results with another year of data collection.
- Challenges
    - Many possible use cases; finding testable use cases (unemployment) based on third party data along with opportunity sizing
    - Data size was relatively small, needed to consider trade off between granularity, aggregation and base validity
    - Convinced team to employ a robust baseline to test for effects from the market research data.
- Skills and learnings
    - I leveraged my experience with market research data to create a robust data ingest pipeline, and to match with BLS unemployment data
    - I used my machine learning expertise to set up experiments including strong baselines to detect the effect of adding signal from client data, using gradient boosted regression trees with time-series considerations
    - I had opportunity to mentor a junior data scientist, and work collaboratively with a project leader. This was a great opportunity to increase personal ownership of project

## High end fashion retailer
#### $52m personalization pilot, sales lift, offers and migration, many new techs and frameworks

- Goal
    - We worked with a high end fashion retailer to drive personalised offers to their customers, with a view to increase revenue via sales lift %.
- Impact
    - Overall the project was a great success, and we showed significant lift above clients BAU (about 25%)
    - I contributed to the project by opportunity sizing and designing sales offers, specifically for cross-shopping recommendations. This was done through a basket analysis style recommendation model based on recent purchases. Ultimately there was no significant effect, but I learnt a lot about the product analytics lifecycle.
    - Client showed great appreciation for training and side-by-side comparison of existing offers
- Challenges
    - I learnt as much as I could about personalization, BCG and client, levels of stakeholders
    - I migrated several existing offer business logic SAS scripts to pyspark - two technologies I was unfamiliar before the case. I leveraged this to train client data science team in python and new infrastructure.
    - Large data sets and new frameworks to learn
- Skills and learnings
    - I was exposed to several new technologies and frameworks and learnt; software engineering skills, SQL for data ingest, github, pyspark, AWS, airflow, SAS
    - I quickly navigated a new work and client work environment, and had a very smooth case experience
    - More recently I learnt that I could have used triggering (compare treatment to existing offer) to potentially increase significance!
- Context
    - Our client regularly provides customers with publicly available sales offers. BCG recommended a personalized marketing approach, as this would match customers segments to best offers and reduce waste
    - As it is a high-margin business, proving sales lift % for overall test/control was our primary metric, as well as within sub-test groups.
    - As first BCG case, worked closely with project leader and regularly requested feedback.
    - I worked with teammates for experiment design; test groups, timing, metrics and  measurement.

## Chatbot for survey engagement
#### New business capability and revenue streams, multi-disciplinary; advanced ML and python infrastructure

- Goal
    - Build a market research survey chatbot to increase respondent engagement and quality of feedback while retaining guardrail metrics, and highlight the company as a key market research innovator and competitive advantage.
- Impact
    - We created a full chatbot solution along with metrics and guardrail metrics, including increased ‘quality’ of information as tested against explainability of overall satisfaction, quantity of text information, while maintaining survey completion rate and unsubscribe rate.
    - The chatbot solution used NLP based models (keywords, sentiment, classification), state machines, and a docker based API to serve chatbot requests to users
- Challenges
    - Hard to identify metrics and quantify improvement
    - Technology challenges early in career
- Skills and learnings
    - Learnt API, state machine frameworks
    - Worked with junior analysts to create effective keyword based hierarchies

## Text analytics capability
#### New business capability and revenue streams, advanced ML and sales

- Goal
    - Open ended text responses in market research surveys a quality source of insights, however these require slow, expensive and manual review. I designed a text classification and sentiment scoring process to quickly and accurately compile insights, in a highly scalable way.
- Impact
    - We successfully piloted the text classification process with a client, enabling them to save $30k per year on text analytics costs
    - We sold several projects based on this capability to other clients, with new revenues of $120k in first year, and $300k in second.
    - We provided scalable sentiment scoring analysis to all projects as client value add.
- Challenges
    - Technical modelling challenges with small categories, complexity of feedback, working with unstructured data
    - Developing a process which was transparent to accuracy, trade-offs, and value
- Skills and learnings
    - Learnt strong python and machine learning fundamentals, advanced text analytics techniques
    - Worked with business owner to productise and sell the innovation to clients

## Government infrastructure end-user research
#### Measuring end-user satisfaction with large scale infrastructure project affecting all Australians

- Goal
    - Assist the client in understanding customer satisfaction with their service and root cause issues across segments
- Impact
    - We surveyed millions of Australian consumers on their infrastructure satisfaction and several points in lifecycle including installation, 3 months, and 6 months into usage.
    - Used robust data science approach to estimate root cause of customer satisfaction, across several segments
- Challenges
    - Large amount of data and weighting requirements
    - Creating automated data ingestion and analysis processes to support early week reporting
    - Creating infrastructure to handle hundreds of linear regressions and random forest based feature importance
- Skills and learnings
    - Python and pandas
    - Ability to break down data and analytical problems into executable code
    - Project mangagement
